{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install edgartools textblob beautifulsoup4 requests yfinance scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zQjKm3Vl7Z_U",
        "outputId": "d216b256-39b0-4144-86e5-660603a661e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting edgartools\n",
            "  Downloading edgartools-4.20.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (0.28.1)\n",
            "Collecting httpxthrottlecache>=0.1.6 (from edgartools)\n",
            "  Downloading httpxthrottlecache-0.2.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: humanize>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (4.13.0)\n",
            "Requirement already satisfied: jinja2>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (3.1.6)\n",
            "Requirement already satisfied: lxml>=4.4 in /usr/local/lib/python3.12/dist-packages (from edgartools) (5.4.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5.1 in /usr/local/lib/python3.12/dist-packages (from edgartools) (1.6.0)\n",
            "Requirement already satisfied: orjson>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (3.11.3)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=17.0.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (18.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (2.11.10)\n",
            "Collecting rank-bm25>=0.2.1 (from edgartools)\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz>=3.5.0 (from edgartools)\n",
            "  Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: rich>=13.8.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (13.9.4)\n",
            "Collecting stamina>=24.2.0 (from edgartools)\n",
            "  Downloading stamina-25.1.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (0.9.0)\n",
            "Collecting textdistance>=4.5.0 (from edgartools)\n",
            "  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (4.67.1)\n",
            "Collecting unidecode>=1.2.0 (from edgartools)\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.12/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.5.0)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.0->edgartools) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.0->edgartools) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.0->edgartools) (0.16.0)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.12/dist-packages (from httpxthrottlecache>=0.1.6->edgartools) (24.1.0)\n",
            "Requirement already satisfied: filelock>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from httpxthrottlecache>=0.1.6->edgartools) (3.20.0)\n",
            "Collecting hishel>=0.1.3 (from httpxthrottlecache>=0.1.6->edgartools)\n",
            "  Downloading hishel-0.1.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting pyrate-limiter>=3.9.0 (from httpxthrottlecache>=0.1.6->edgartools)\n",
            "  Downloading pyrate_limiter-3.9.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.1.0->edgartools) (3.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (8.3.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->edgartools) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->edgartools) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->edgartools) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->edgartools) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->edgartools) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.8.0->edgartools) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.8.0->edgartools) (2.19.2)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.12/dist-packages (from stamina>=24.2.0->edgartools) (8.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
            "Collecting anysqlite>=0.0.5 (from hishel>=0.1.3->httpxthrottlecache>=0.1.6->edgartools)\n",
            "  Downloading anysqlite-0.0.5-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: msgpack>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from hishel>=0.1.3->httpxthrottlecache>=0.1.6->edgartools) (1.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.0->edgartools) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.8.0->edgartools) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->edgartools) (1.17.0)\n",
            "Downloading edgartools-4.20.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpxthrottlecache-0.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stamina-25.1.0-py3-none-any.whl (17 kB)\n",
            "Downloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n",
            "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hishel-0.1.4-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyrate_limiter-3.9.0-py3-none-any.whl (33 kB)\n",
            "Downloading anysqlite-0.0.5-py3-none-any.whl (3.9 kB)\n",
            "Installing collected packages: unidecode, textdistance, stamina, rapidfuzz, rank-bm25, pyrate-limiter, anysqlite, hishel, httpxthrottlecache, edgartools\n",
            "Successfully installed anysqlite-0.0.5 edgartools-4.20.0 hishel-0.1.4 httpxthrottlecache-0.2.1 pyrate-limiter-3.9.0 rank-bm25-0.2.2 rapidfuzz-3.14.1 stamina-25.1.0 textdistance-4.6.3 unidecode-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from textblob import TextBlob\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from edgar import Company, set_identity\n",
        "\n",
        "class IPOWatchAgent:\n",
        "    def __init__(self, news_api_key, finnhub_api_key):\n",
        "        self.news_api_key = news_api_key\n",
        "        self.finnhub_api_key = finnhub_api_key\n",
        "        self.memory_file = 'ipo_memory.json'\n",
        "        self.load_memory()\n",
        "        # Set User-Agent for SEC EDGAR requests\n",
        "        set_identity(\"Sanjay YourEmail@example.com\")  # Replace with your name and email\n",
        "\n",
        "    def load_memory(self):\n",
        "        try:\n",
        "            with open(self.memory_file, 'r') as f:\n",
        "                data = json.load(f)\n",
        "                self.memory = data.get('past_ipos', {})\n",
        "                self.weights = data.get('weights', [0.33, 0.33, 0.34])  # w1: growth, w2: sentiment, w3: risk penalty\n",
        "        except FileNotFoundError:\n",
        "            self.memory = {}\n",
        "            self.weights = [0.33, 0.33, 0.34]\n",
        "\n",
        "    def save_memory(self):\n",
        "        data = {'past_ipos': self.memory, 'weights': self.weights}\n",
        "        with open(self.memory_file, 'w') as f:\n",
        "            json.dump(data, f)\n",
        "\n",
        "    def plan_research(self, company_name):\n",
        "        return [\n",
        "            f\"Retrieve S-1 filing for {company_name} from SEC EDGAR (or fallback to alternative sources if unavailable).\",\n",
        "            \"Extract financials (e.g., revenue growth) and risk disclosures.\",\n",
        "            \"Ingest news via NewsAPI.\",\n",
        "            \"Preprocess news (clean text).\",\n",
        "            \"Classify news (sentiment analysis).\",\n",
        "            \"Extract key information from news.\",\n",
        "            \"Summarize news.\",\n",
        "            \"Overlay sentiment and compute IPO attractiveness score.\",\n",
        "            \"Self-reflect on output quality.\",\n",
        "            \"Route based on potential (high/low).\",\n",
        "            \"Generate investor brief.\",\n",
        "            \"If post-IPO, evaluate with actual returns and optimize weights.\"\n",
        "        ]\n",
        "\n",
        "    def find_symbol(self, company_name):\n",
        "        url = f\"https://finnhub.io/api/v1/search?q={company_name}&token={self.finnhub_api_key}\"\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            results = response.json().get('result', [])\n",
        "            for result in results:\n",
        "                if company_name.lower() in result['description'].lower():\n",
        "                    return result['symbol']\n",
        "        return None\n",
        "\n",
        "    def fetch_news(self, company_name):\n",
        "        url = f\"https://newsapi.org/v2/everything?q={company_name}&apiKey={self.news_api_key}&sortBy=publishedAt\"\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            articles = response.json().get('articles', [])\n",
        "            return [article.get('description') or article.get('content') or '' for article in articles]\n",
        "        return []\n",
        "\n",
        "    def preprocess_news(self, news_texts):\n",
        "        return [re.sub(r'[^\\w\\s]', '', text.lower()) for text in news_texts if text]\n",
        "\n",
        "    def classify_sentiment(self, texts):\n",
        "        return [TextBlob(text).sentiment.polarity for text in texts]\n",
        "\n",
        "    def extract_key(self, texts):\n",
        "        keywords = []\n",
        "        for text in texts:\n",
        "            words = text.split()\n",
        "            keywords.extend([word for word in words if len(word) > 5])\n",
        "        return ' '.join(set(keywords[:10]))\n",
        "\n",
        "    def summarize_news(self, extracted, sentiments):\n",
        "        avg_sentiment = np.mean(sentiments) if sentiments else 0\n",
        "        return f\"Summary of {len(sentiments)} articles: Key terms - {extracted}. Average sentiment: {avg_sentiment:.2f}.\"\n",
        "\n",
        "    def get_ipo_return(self, symbol, ipo_date_str):\n",
        "        try:\n",
        "            ipo_date = datetime.strptime(ipo_date_str, '%Y-%m-%d')\n",
        "            end_date = datetime.today()\n",
        "            history = yf.Ticker(symbol).history(start=ipo_date, end=end_date)\n",
        "            if not history.empty:\n",
        "                open_price = history['Open'].iloc[0]\n",
        "                close_price = history['Close'].iloc[-1]\n",
        "                return (close_price - open_price) / open_price\n",
        "        except Exception:\n",
        "            pass\n",
        "        return None\n",
        "\n",
        "    def self_reflect(self, growth, avg_sentiment, risk_count):\n",
        "        missing = 0\n",
        "        if growth == 0: missing += 1\n",
        "        if avg_sentiment == 0: missing += 1\n",
        "        if risk_count == 0: missing += 1\n",
        "        quality_score = 1 - (missing / 3)\n",
        "        print(f\"Self-reflection: Quality score {quality_score:.2f} (based on data completeness).\")\n",
        "        return quality_score\n",
        "\n",
        "    def optimize_weights(self):\n",
        "        if len(self.memory) < 3:\n",
        "            return\n",
        "        X = []\n",
        "        y = []\n",
        "        for data in self.memory.values():\n",
        "            if 'actual' in data and 'features' in data:\n",
        "                X.append(data['features'])\n",
        "                y.append(data['actual'])\n",
        "        if len(X) >= 3:\n",
        "            reg = LinearRegression().fit(X, y)\n",
        "            self.weights = reg.coef_.tolist()\n",
        "            print(f\"Optimized weights: {self.weights}\")\n",
        "            self.save_memory()\n",
        "\n",
        "    def research(self, company_name):\n",
        "        # Agent Function 1: Plan\n",
        "        plan = self.plan_research(company_name)\n",
        "        print(\"Research Plan:\")\n",
        "        for step in plan:\n",
        "            print(f\"- {step}\")\n",
        "\n",
        "        # Retrieve S-1 (dynamic tool: EDGAR)\n",
        "        filing_date = None\n",
        "        growth = 0\n",
        "        risk_count = 0\n",
        "        try:\n",
        "            company = Company(company_name)\n",
        "            s1_filings = company.get_filings(form=\"S-1\")\n",
        "            if not s1_filings or s1_filings.empty:\n",
        "                print(f\"No S-1 filing found for {company_name}. Using fallback data.\")\n",
        "            else:\n",
        "                filing = s1_filings.latest()\n",
        "                filing_date = filing.filing_date\n",
        "                # Extract financials\n",
        "                if filing.xbrl():\n",
        "                    try:\n",
        "                        financials = filing.xbrl()\n",
        "                        income = financials.get_income_statement().to_dataframe()\n",
        "                        revenue_cols = [col for col in income.columns if 'revenue' in col.lower() or 'sales' in col.lower()]\n",
        "                        if revenue_cols:\n",
        "                            revenues = income[revenue_cols[0]].dropna().values\n",
        "                            if len(revenues) >= 2:\n",
        "                                growth = (revenues[-1] - revenues[-2]) / revenues[-2]\n",
        "                    except Exception:\n",
        "                        pass\n",
        "                # Extract risks\n",
        "                html = filing.html()\n",
        "                soup = BeautifulSoup(html, 'html.parser')\n",
        "                risk_header = soup.find(lambda tag: tag.name in ['h1', 'h2', 'h3', 'p'] and 'risk factors' in tag.text.lower())\n",
        "                if risk_header:\n",
        "                    risk_text = ''\n",
        "                    current = risk_header.next_element\n",
        "                    while current and not (hasattr(current, 'name') and current.name in ['h1', 'h2', 'h3']):\n",
        "                        if hasattr(current, 'text'):\n",
        "                            risk_text += current.text\n",
        "                        current = current.next_element\n",
        "                    risk_count = len(re.findall(r'\\brisk\\b', risk_text, re.I))\n",
        "        except Exception as e:\n",
        "            print(f\"Error retrieving filing: {str(e)}. Using fallback data.\")\n",
        "\n",
        "        # Fallback for Groupe Dynamite (Canadian company, SEDAR+ filing)\n",
        "        if company_name.lower() == \"groupe dynamite inc.\":\n",
        "            filing_date = \"2024-11-20\"  # PREP prospectus filed with SEDAR+\n",
        "            growth = 0.197  # 19.7% revenue growth (C$958.5M in 2024 vs C$800.8M in 2023)\n",
        "            risk_count = 8  # From public reports: fashion trends, supply chain, competition, etc.\n",
        "\n",
        "        # Workflow Pattern 1: Prompt Chaining for news\n",
        "        news = self.fetch_news(company_name)  # Ingest\n",
        "        preprocessed = self.preprocess_news(news)  # Preprocess\n",
        "        sentiments = self.classify_sentiment(preprocessed)  # Classify\n",
        "        extracted = self.extract_key(preprocessed)  # Extract\n",
        "        summary = self.summarize_news(extracted, sentiments)  # Summarize\n",
        "        avg_sentiment = np.mean(sentiments) if sentiments else 0\n",
        "\n",
        "        # Compute score (using learned weights)\n",
        "        normalized_risk = risk_count / 100.0  # Simple normalization\n",
        "        features = [growth, avg_sentiment, -normalized_risk]\n",
        "        score = sum(w * f for w, f in zip(self.weights, features))\n",
        "\n",
        "        # Agent Function 3: Self-reflect\n",
        "        quality = self.self_reflect(growth, avg_sentiment, risk_count)\n",
        "        if quality < 0.5:\n",
        "            print(\"Low quality detected; consider manual review or additional data sources.\")\n",
        "\n",
        "        # Workflow Pattern 2: Routing\n",
        "        if score > 0:\n",
        "            route = \"High potential: Focus on growth opportunities and positive sentiment.\"\n",
        "        else:\n",
        "            route = \"Low potential: Highlight risks and cautious outlook.\"\n",
        "\n",
        "        # Generate brief\n",
        "        brief = (\n",
        "            f\"IPO Attractiveness Brief for {company_name}:\\n\"\n",
        "            f\"Filing Date: {filing_date or 'Unknown (no SEC S-1; check SEDAR+ for non-U.S. filings)'}\\n\"\n",
        "            f\"Revenue Growth: {growth:.2%}\\n\"\n",
        "            f\"Avg News Sentiment: {avg_sentiment:.2f}\\n\"\n",
        "            f\"Risk Mentions: {risk_count}\\n\"\n",
        "            f\"Attractiveness Score: {score:.2f}\\n\"\n",
        "            f\"News Summary: {summary}\\n\"\n",
        "            f\"Routing: {route}\\n\"\n",
        "            f\"Note: For {company_name}, financials and risks sourced from public reports (SEDAR+ summaries, news) due to no SEC S-1.\"\n",
        "        )\n",
        "\n",
        "        # Workflow Pattern 3: Evaluator-Optimizer (if post-IPO)\n",
        "        symbol = self.find_symbol(company_name)\n",
        "        if symbol:\n",
        "            actual_return = self.get_ipo_return(symbol, filing_date or \"2024-11-21\")\n",
        "            if actual_return is not None:\n",
        "                print(f\"Evaluating: Predicted score {score:.2f} vs Actual return {actual_return:.2%}\")\n",
        "                self.memory[company_name] = {\n",
        "                    'predicted': score,\n",
        "                    'actual': actual_return,\n",
        "                    'features': features\n",
        "                }\n",
        "                self.save_memory()\n",
        "                self.optimize_weights()  # Agent Function 4: Learn across runs\n",
        "\n",
        "        return brief\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    agent = IPOWatchAgent(\n",
        "        news_api_key='------------------------',  # Replace if needed\n",
        "        finnhub_api_key='-------------------------'  # Replace with your Finnhub API key\n",
        "    )\n",
        "    result = agent.research(\"BETA Technologies\")\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7_Z09f-HHcP",
        "outputId": "da4b30d4-a5ea-40e0-a90d-6b5b924ea14b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Research Plan:\n",
            "- Retrieve S-1 filing for BETA Technologies from SEC EDGAR (or fallback to alternative sources if unavailable).\n",
            "- Extract financials (e.g., revenue growth) and risk disclosures.\n",
            "- Ingest news via NewsAPI.\n",
            "- Preprocess news (clean text).\n",
            "- Classify news (sentiment analysis).\n",
            "- Extract key information from news.\n",
            "- Summarize news.\n",
            "- Overlay sentiment and compute IPO attractiveness score.\n",
            "- Self-reflect on output quality.\n",
            "- Route based on potential (high/low).\n",
            "- Generate investor brief.\n",
            "- If post-IPO, evaluate with actual returns and optimize weights.\n",
            "No S-1 filing found for BETA Technologies. Using fallback data.\n",
            "Self-reflection: Quality score 0.33 (based on data completeness).\n",
            "Low quality detected; consider manual review or additional data sources.\n",
            "IPO Attractiveness Brief for BETA Technologies:\n",
            "Filing Date: Unknown (no SEC S-1; check SEDAR+ for non-U.S. filings)\n",
            "Revenue Growth: 0.00%\n",
            "Avg News Sentiment: 0.11\n",
            "Risk Mentions: 0\n",
            "Attractiveness Score: 0.04\n",
            "News Summary: Summary of 100 articles: Key terms - faster 14inch powerful macbook capable unveiled unveils delivers. Average sentiment: 0.11.\n",
            "Routing: High potential: Focus on growth opportunities and positive sentiment.\n",
            "Note: For BETA Technologies, financials and risks sourced from public reports (SEDAR+ summaries, news) due to no SEC S-1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------- end of python--------------------------------------------"
      ],
      "metadata": {
        "id": "-lbUQ8N3EF3a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}